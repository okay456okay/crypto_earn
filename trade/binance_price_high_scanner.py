#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
Binanceä»·æ ¼é«˜ç‚¹æ‰«æå™¨

è¯¥è„šæœ¬ç”¨äºæ‰«æBinanceæ‰€æœ‰åˆçº¦äº¤æ˜“å¯¹ï¼Œç›‘æ§ä»·æ ¼çªç ´æƒ…å†µï¼š
1. è·å–æ‰€æœ‰åˆçº¦å¯¹è¿‘30å¤©çš„30åˆ†é’ŸKçº¿æ•°æ®
2. æ£€æŸ¥æœ€åä¸€æ ¹Kçº¿ä»·æ ¼æ˜¯å¦ä¸º30å¤©æœ€é«˜ç‚¹
3. å¦‚æœæ˜¯æœ€é«˜ç‚¹ï¼Œå‘é€ä¼ä¸šå¾®ä¿¡ç¾¤æœºå™¨äººé€šçŸ¥

é€šçŸ¥å†…å®¹åŒ…å«ï¼š
- å½“å‰ä»·æ ¼
- èµ„é‡‘è´¹ç‡ã€èµ„é‡‘è´¹ç»“ç®—å‘¨æœŸ
- å†å²æœ€é«˜ä»·ã€å†å²æœ€ä½ä»·ã€å¸‚å€¼ã€Twitter IDã€Githubåœ°å€ã€å‘è¡Œæ—¥æœŸ
- åˆçº¦æè¿°
- åˆçº¦tags

ä½œè€…: Claude
åˆ›å»ºæ—¶é—´: 2024-12-30
"""

import os
import sys
sys.path.append(os.path.join(os.path.dirname(os.path.abspath(__file__)), '..'))

from tools.logger import logger
from config import binance_api_key, binance_api_secret, proxies, project_root
from binance.client import Client
from binance.exceptions import BinanceAPIException
import time
import json
import pandas as pd
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional, Tuple
import logging
import requests
import pickle
import hashlib
import argparse

# è®¾ç½®æ—¥å¿—çº§åˆ«
logger.setLevel(logging.INFO)

class BinancePriceHighScanner:
    """Binanceä»·æ ¼é«˜ç‚¹æ‰«æå™¨"""
    
    def __init__(self, api_key: str = None, api_secret: str = None, days_to_analyze: int = 30):
        """
        åˆå§‹åŒ–Binanceå®¢æˆ·ç«¯
        
        Args:
            api_key: Binance API Key
            api_secret: Binance API Secret
            days_to_analyze: åˆ†æå†å²å¤©æ•°
        """
        self.client = Client(
            api_key or binance_api_key, 
            api_secret or binance_api_secret,
            requests_params={'proxies': proxies}
        )
        
        # ä¼ä¸šå¾®ä¿¡ç¾¤æœºå™¨äººwebhook
        self.webhook_url = "https://qyapi.weixin.qq.com/cgi-bin/webhook/send?key=43c4c655-b144-4e1f-b054-4b3a9e2caf26"
        
        # åˆ†æå¤©æ•°
        self.days_to_analyze = days_to_analyze
        
        # ç¼“å­˜ç›®å½•
        self.cache_dir = os.path.join(project_root, 'trade/cache')
        os.makedirs(self.cache_dir, exist_ok=True)
        
        # ç¼“å­˜æ–‡ä»¶è·¯å¾„
        self.token_info_cache = os.path.join(self.cache_dir, 'token_info_cache.pkl')
        self.symbol_description_cache = os.path.join(self.cache_dir, 'symbol_description_cache.pkl')
        self.products_cache = os.path.join(self.cache_dir, 'products_cache.pkl')
        
        # ç¼“å­˜è¿‡æœŸæ—¶é—´ï¼ˆ1å¤©ï¼‰
        self.cache_expire_hours = 24
        
        # åŠ è½½ç¼“å­˜æ•°æ®
        self.token_info_data = self.load_cache_with_expiry(self.token_info_cache)
        self.symbol_description_data = self.load_cache_with_expiry(self.symbol_description_cache)
        self.products_data = self.load_cache_with_expiry(self.products_cache)
        
        logger.info(f"Binanceä»·æ ¼é«˜ç‚¹æ‰«æå™¨åˆå§‹åŒ–å®Œæˆï¼Œåˆ†æå¤©æ•°: {self.days_to_analyze}å¤©")

    def load_cache_with_expiry(self, cache_file: str) -> Dict:
        """åŠ è½½å¸¦è¿‡æœŸæ—¶é—´çš„ç¼“å­˜æ•°æ®"""
        try:
            if os.path.exists(cache_file):
                with open(cache_file, 'rb') as f:
                    cache_data = pickle.load(f)
                
                # æ£€æŸ¥ç¼“å­˜æ ¼å¼å’Œè¿‡æœŸæ—¶é—´
                if isinstance(cache_data, dict) and 'timestamp' in cache_data and 'data' in cache_data:
                    cache_time = datetime.fromtimestamp(cache_data['timestamp'])
                    current_time = datetime.now()
                    
                    # æ£€æŸ¥æ˜¯å¦è¿‡æœŸ
                    if (current_time - cache_time).total_seconds() < self.cache_expire_hours * 3600:
                        logger.info(f"åŠ è½½æœ‰æ•ˆç¼“å­˜: {cache_file}ï¼Œç¼“å­˜æ—¶é—´: {cache_time.strftime('%Y-%m-%d %H:%M:%S')}")
                        return cache_data['data']
                    else:
                        logger.info(f"ç¼“å­˜å·²è¿‡æœŸ: {cache_file}ï¼Œå°†é‡æ–°è·å–æ•°æ®")
                        return {}
                else:
                    # æ—§æ ¼å¼ç¼“å­˜ï¼Œæ¸…é™¤é‡æ–°è·å–
                    logger.info(f"æ—§æ ¼å¼ç¼“å­˜: {cache_file}ï¼Œå°†é‡æ–°è·å–æ•°æ®")
                    return {}
        except Exception as e:
            logger.warning(f"åŠ è½½ç¼“å­˜æ–‡ä»¶ {cache_file} å¤±è´¥: {str(e)}")
        return {}

    def save_cache_with_expiry(self, cache_file: str, data: Dict):
        """ä¿å­˜å¸¦è¿‡æœŸæ—¶é—´çš„ç¼“å­˜æ•°æ®"""
        try:
            cache_data = {
                'timestamp': time.time(),
                'data': data
            }
            with open(cache_file, 'wb') as f:
                pickle.dump(cache_data, f)
            logger.debug(f"ç¼“å­˜å·²ä¿å­˜: {cache_file}")
        except Exception as e:
            logger.error(f"ä¿å­˜ç¼“å­˜æ–‡ä»¶ {cache_file} å¤±è´¥: {str(e)}")

    def load_cache(self, cache_file: str) -> Dict:
        """åŠ è½½ç¼“å­˜æ•°æ®ï¼ˆå…¼å®¹æ—§æ–¹æ³•ï¼‰"""
        return self.load_cache_with_expiry(cache_file)

    def save_cache(self, cache_file: str, data: Dict):
        """ä¿å­˜ç¼“å­˜æ•°æ®ï¼ˆå…¼å®¹æ—§æ–¹æ³•ï¼‰"""
        self.save_cache_with_expiry(cache_file, data)

    def get_all_futures_symbols(self) -> List[str]:
        """
        è·å–æ‰€æœ‰åˆçº¦äº¤æ˜“å¯¹ç¬¦å·
        
        Returns:
            List[str]: äº¤æ˜“å¯¹ç¬¦å·åˆ—è¡¨
        """
        try:
            logger.info("è·å–Binanceæ‰€æœ‰åˆçº¦äº¤æ˜“å¯¹...")
            exchange_info = self.client.futures_exchange_info()
            
            symbols = []
            for symbol_info in exchange_info['symbols']:
                if (symbol_info['status'] == 'TRADING' and 
                    symbol_info['contractType'] == 'PERPETUAL' and
                    symbol_info['quoteAsset'] == 'USDT'):
                    symbols.append(symbol_info['symbol'])
            
            logger.info(f"æ‰¾åˆ° {len(symbols)} ä¸ªæ´»è·ƒçš„USDTæ°¸ç»­åˆçº¦äº¤æ˜“å¯¹")
            return symbols
            
        except Exception as e:
            logger.error(f"è·å–åˆçº¦äº¤æ˜“å¯¹ä¿¡æ¯å¤±è´¥: {str(e)}")
            return []

    def get_30min_klines(self, symbol: str, days: int = None) -> Optional[List[List]]:
        """
        è·å–30åˆ†é’ŸKçº¿æ•°æ®
        https://developers.binance.com/docs/derivatives/usds-margined-futures/market-data/rest-api/Kline-Candlestick-Data
        Args:
            symbol: äº¤æ˜“å¯¹ç¬¦å·
            days: è·å–å¤©æ•°ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨å®ä¾‹çš„é»˜è®¤å€¼
            
        Returns:
            List[List]: Kçº¿æ•°æ®åˆ—è¡¨
        [
            [
                1499040000000,      // Open time
                "0.01634790",       // Open
                "0.80000000",       // High
                "0.01575800",       // Low
                "0.01577100",       // Close
                "148976.11427815",  // Volume
                1499644799999,      // Close time
                "2434.19055334",    // Quote asset volume
                308,                // Number of trades
                "1756.87402397",    // Taker buy base asset volume
                "28.46694368",      // Taker buy quote asset volume
                "17928899.62484339" // Ignore.
            ]
        ]
    """
        if days is None:
            days = self.days_to_analyze
            
        try:
            # è®¡ç®—æ—¶é—´èŒƒå›´
            end_time = datetime.now()
            start_time = end_time - timedelta(days=days)
            
            # è·å–30åˆ†é’ŸKçº¿æ•°æ®
            klines = self.client.futures_klines(
                symbol=symbol,
                interval=Client.KLINE_INTERVAL_30MINUTE,
                startTime=int(start_time.timestamp() * 1000),
                endTime=int(end_time.timestamp() * 1000),
                limit=1440  # 30å¤©*24å°æ—¶*2(30åˆ†é’Ÿ) = 1440, Default 500; max 1500.
            )
            
            if not klines:
                logger.warning(f"{symbol}: æœªè·å–åˆ°Kçº¿æ•°æ®")
                return None
                
            logger.debug(f"{symbol}: è·å–åˆ°{len(klines)}æ ¹30åˆ†é’ŸKçº¿")
            return klines
            
        except Exception as e:
            logger.error(f"è·å–{symbol}çš„30åˆ†é’ŸKçº¿æ•°æ®å¤±è´¥: {str(e)}")
            return None

    def check_price_breakouts(self, klines: List[List]) -> Dict[str, Any]:
        """
        æ£€æŸ¥æœ€åä¸€æ ¹Kçº¿ä»·æ ¼æ˜¯å¦ä¸ºå¤šä¸ªæ—¶é—´åŒºé—´çš„æœ€é«˜ç‚¹
        
        Args:
            klines: Kçº¿æ•°æ®åˆ—è¡¨ï¼ˆ30å¤©çš„30åˆ†é’ŸKçº¿ï¼‰
            
        Returns:
            Dict: åŒ…å«å½“å‰ä»·æ ¼å’Œå„æ—¶é—´åŒºé—´çªç ´ä¿¡æ¯çš„å­—å…¸
            {
                'current_price': float,
                'has_breakout': bool,
                'breakout_periods': list,
                'breakouts': {
                    7: {'is_high': bool, 'max_high': float, 'min_low': float},
                    15: {'is_high': bool, 'max_high': float, 'min_low': float},
                    30: {'is_high': bool, 'max_high': float, 'min_low': float}
                }
            }
        """
        if not klines or len(klines) == 0:
            return {
                'current_price': 0.0,
                'has_breakout': False,
                'breakout_periods': [],
                'breakouts': {}
            }
        
        # è·å–æœ€åä¸€æ ¹Kçº¿çš„æ”¶ç›˜ä»·
        current_price = float(klines[-1][4])  # ç´¢å¼•4æ˜¯æ”¶ç›˜ä»·
        
        # æ¯30åˆ†é’Ÿä¸€æ ¹Kçº¿ï¼Œè®¡ç®—å„æ—¶é—´åŒºé—´å¯¹åº”çš„Kçº¿æ•°é‡
        periods = {
            7: 7 * 24 * 2,    # 7å¤© = 7 * 24å°æ—¶ * 2(æ¯å°æ—¶2æ ¹30åˆ†é’ŸKçº¿) = 336æ ¹
            15: 15 * 24 * 2,  # 15å¤© = 720æ ¹
            30: 30 * 24 * 2   # 30å¤© = 1440æ ¹
        }
        
        breakouts = {}
        breakout_periods = []
        has_breakout = False
        
        for days, kline_count in periods.items():
            # ç¡®ä¿ä¸è¶…è¿‡å®é™…Kçº¿æ•°é‡
            actual_count = min(kline_count, len(klines) - 1)  # æ’é™¤æœ€åä¸€æ ¹Kçº¿
            
            if actual_count <= 0:
                breakouts[days] = {
                    'is_high': False,
                    'max_high': 0.0,
                    'min_low': 0.0
                }
                continue
            
            # è·å–æŒ‡å®šæ—¶é—´åŒºé—´çš„Kçº¿æ•°æ®ï¼ˆä»å€’æ•°ç¬¬äºŒæ ¹å¼€å§‹å¾€å‰æ•°ï¼‰
            period_klines = klines[-(actual_count+1):-1]  # æ’é™¤æœ€åä¸€æ ¹Kçº¿
            
            # æå–è¯¥æ—¶é—´åŒºé—´çš„é«˜ç‚¹å’Œä½ç‚¹ä»·æ ¼
            high_prices = [float(kline[2]) for kline in period_klines]  # ç´¢å¼•2æ˜¯é«˜ç‚¹ä»·æ ¼
            low_prices = [float(kline[3]) for kline in period_klines]   # ç´¢å¼•3æ˜¯ä½ç‚¹ä»·æ ¼
            
            if high_prices and low_prices:
                max_high = max(high_prices)
                min_low = min(low_prices)
                
                # æ£€æŸ¥å½“å‰ä»·æ ¼æ˜¯å¦ç­‰äºæˆ–è¶…è¿‡è¯¥æ—¶é—´åŒºé—´çš„æœ€é«˜ç‚¹
                is_high = current_price >= max_high
                
                breakouts[days] = {
                    'is_high': is_high,
                    'max_high': max_high,
                    'min_low': min_low
                }
                
                if is_high:
                    breakout_periods.append(days)
                    has_breakout = True
            else:
                breakouts[days] = {
                    'is_high': False,
                    'max_high': 0.0,
                    'min_low': 0.0
                }
        
        return {
            'current_price': current_price,
            'has_breakout': has_breakout,
            'breakout_periods': breakout_periods,
            'breakouts': breakouts
        }

    def get_funding_rate_info(self, symbol: str) -> Dict[str, Any]:
        """
        è·å–èµ„é‡‘è´¹ç‡ä¿¡æ¯
        
        Args:
            symbol: äº¤æ˜“å¯¹ç¬¦å·
            
        Returns:
            Dict: èµ„é‡‘è´¹ç‡ä¿¡æ¯
        """
        try:
            # è·å–å½“å‰èµ„é‡‘è´¹ç‡
            funding_rate = self.client.futures_funding_rate(symbol=symbol, limit=1)
            
            if funding_rate:
                current_rate = float(funding_rate[0]['fundingRate'])
                # èµ„é‡‘è´¹ç‡é€šå¸¸æ¯8å°æ—¶ç»“ç®—ä¸€æ¬¡
                settlement_hours = 8
                # å¹´åŒ–èµ„é‡‘è´¹ç‡ = å½“å‰è´¹ç‡ * (365 * 24 / 8) * 100
                annualized_rate = current_rate * (365 * 24 / settlement_hours) * 100
                
                return {
                    'current_rate': current_rate,
                    'current_rate_percent': current_rate * 100,
                    'annualized_rate': annualized_rate,
                    'settlement_hours': settlement_hours
                }
            
        except Exception as e:
            logger.error(f"è·å–{symbol}èµ„é‡‘è´¹ç‡å¤±è´¥: {str(e)}")
        
        return {
            'current_rate': 0.0,
            'current_rate_percent': 0.0,
            'annualized_rate': 0.0,
            'settlement_hours': 8
        }

    def get_token_info(self, base_asset: str) -> Dict[str, Any]:
        """
        è·å–ä»£å¸è¯¦ç»†ä¿¡æ¯ï¼ˆå¸¦ç¼“å­˜ï¼‰
        
        Args:
            base_asset: åŸºç¡€èµ„äº§ç¬¦å·
            
        Returns:
            Dict: ä»£å¸ä¿¡æ¯
        """
        # æ£€æŸ¥ç¼“å­˜
        if base_asset in self.token_info_data:
            return self.token_info_data[base_asset]
        
        try:
            url = f"https://www.binance.com/bapi/apex/v1/friendly/apex/marketing/web/token-info?symbol={base_asset}"
            
            response = requests.get(url, proxies=proxies, timeout=10)
            response.raise_for_status()
            
            data = response.json()
            
            if data.get('success') and data.get('data'):
                token_data = data['data']
                
                info = {
                    'market_cap': token_data.get('fdmc', 0),  # å®Œå…¨ç¨€é‡Šå¸‚å€¼
                    'ath_price': token_data.get('athpu', 0),  # å†å²æœ€é«˜ä»·
                    'atl_price': token_data.get('atlpu', 0),  # å†å²æœ€ä½ä»·
                    'twitter_username': token_data.get('xhn', ''),  # Twitterç”¨æˆ·å
                    'github_url': token_data.get('ru', ''),  # Githubåœ°å€
                    'launch_date': token_data.get('ald', 0),  # å‘è¡Œæ—¥æœŸæ—¶é—´æˆ³
                    'website_url': token_data.get('ws', ''),  # å®˜ç½‘åœ°å€
                    'description': token_data.get('dbk', ''),  # æè¿°key
                    'market_dominance': token_data.get('dmc', 0),  # å¸‚åœºå ç”¨ç‡
                    'market_rank': token_data.get('rk', 0),  # å¸‚å€¼æ’å
                    'twitter_last_update': token_data.get('xlut', 0),  # Twitteræœ€åæ›´æ–°æ—¶é—´
                    'repo_update_time': token_data.get('rut', 0),  # ä»“åº“æ›´æ–°æ—¶é—´
                }
                
                # æ ¼å¼åŒ–å‘è¡Œæ—¥æœŸ
                if info['launch_date']:
                    try:
                        launch_datetime = datetime.fromtimestamp(info['launch_date'] / 1000)
                        info['launch_date_str'] = launch_datetime.strftime('%Y-%m-%d')
                    except:
                        info['launch_date_str'] = 'Unknown'
                else:
                    info['launch_date_str'] = 'Unknown'
                
                # æ ¼å¼åŒ–Twitteræœ€åæ›´æ–°æ—¶é—´
                if info['twitter_last_update']:
                    try:
                        twitter_datetime = datetime.fromtimestamp(info['twitter_last_update'] / 1000)
                        info['twitter_last_update_str'] = twitter_datetime.strftime('%Y-%m-%d %H:%M')
                    except:
                        info['twitter_last_update_str'] = 'Unknown'
                else:
                    info['twitter_last_update_str'] = 'Unknown'
                
                # æ ¼å¼åŒ–ä»“åº“æ›´æ–°æ—¶é—´
                if info['repo_update_time']:
                    try:
                        repo_datetime = datetime.fromtimestamp(info['repo_update_time'] / 1000)
                        info['repo_update_time_str'] = repo_datetime.strftime('%Y-%m-%d %H:%M')
                    except:
                        info['repo_update_time_str'] = 'Unknown'
                else:
                    info['repo_update_time_str'] = 'Unknown'
                
                # ç¼“å­˜æ•°æ®
                self.token_info_data[base_asset] = info
                self.save_cache_with_expiry(self.token_info_cache, self.token_info_data)
                
                return info
            
        except Exception as e:
            logger.error(f"è·å–{base_asset}ä»£å¸ä¿¡æ¯å¤±è´¥: {str(e)}")
        
        # è¿”å›é»˜è®¤å€¼
        default_info = {
            'market_cap': 0,
            'ath_price': 0,
            'atl_price': 0,
            'twitter_username': '',
            'github_url': '',
            'launch_date': 0,
            'launch_date_str': 'Unknown',
            'website_url': '',
            'description': '',
            'market_dominance': 0,
            'market_rank': 0,
            'twitter_last_update': 0,
            'twitter_last_update_str': 'Unknown',
            'repo_update_time': 0,
            'repo_update_time_str': 'Unknown'
        }
        
        # ç¼“å­˜é»˜è®¤å€¼ä»¥é¿å…é‡å¤è¯·æ±‚
        self.token_info_data[base_asset] = default_info
        self.save_cache_with_expiry(self.token_info_cache, self.token_info_data)
        
        return default_info

    def get_symbol_description(self, symbol: str) -> str:
        """
        è·å–åˆçº¦æè¿°ï¼ˆå¸¦ç¼“å­˜ï¼‰
        
        Args:
            symbol: äº¤æ˜“å¯¹ç¬¦å·
            
        Returns:
            str: åˆçº¦æè¿°
        """
        # æ£€æŸ¥ç¼“å­˜
        if symbol in self.symbol_description_data:
            return self.symbol_description_data[symbol]
        
        try:
            # å¦‚æœç¼“å­˜ä¸ºç©ºï¼Œä¸€æ¬¡æ€§è·å–æ‰€æœ‰æè¿°
            if not self.symbol_description_data:
                url = "https://bin.bnbstatic.com/api/i18n/-/web/cms/en/symbol-description"
                
                response = requests.get(url, proxies=proxies, timeout=10)
                response.raise_for_status()
                
                data = response.json()
                
                # è§£ææ‰€æœ‰ç¬¦å·æè¿°
                if isinstance(data, dict):
                    for key, value in data.items():
                        if isinstance(value, str):
                            # æå–ç¬¦å·åï¼ˆé€šå¸¸æ ¼å¼ä¸ºsymbol_desc_XXXï¼‰
                            if key.startswith('symbol_desc_'):
                                symbol_name = key.replace('symbol_desc_', '')
                                self.symbol_description_data[symbol_name] = value
                
                # ä¿å­˜ç¼“å­˜
                self.save_cache_with_expiry(self.symbol_description_cache, self.symbol_description_data)
                
                logger.info(f"è·å–åˆ°{len(self.symbol_description_data)}ä¸ªç¬¦å·æè¿°")
            
            # ä»ç¼“å­˜ä¸­è·å–æè¿°
            return self.symbol_description_data.get(symbol.replace('USDT', ''), f"No description for {symbol}")
            
        except Exception as e:
            logger.error(f"è·å–{symbol}æè¿°å¤±è´¥: {str(e)}")
            return f"Failed to get description for {symbol}"

    def get_symbol_tags(self, symbol: str) -> List[str]:
        """
        è·å–åˆçº¦æ ‡ç­¾ï¼ˆå¸¦ç¼“å­˜ï¼‰
        
        Args:
            symbol: äº¤æ˜“å¯¹ç¬¦å·
            
        Returns:
            List[str]: æ ‡ç­¾åˆ—è¡¨
        """
        # æ£€æŸ¥ç¼“å­˜
        if symbol in self.products_data:
            return self.products_data[symbol]
        
        try:
            # å¦‚æœç¼“å­˜ä¸ºç©ºï¼Œä¸€æ¬¡æ€§è·å–æ‰€æœ‰äº§å“æ•°æ®
            if not self.products_data:
                url = "https://www.binance.com/bapi/asset/v2/public/asset-service/product/get-products"
                
                response = requests.get(url, proxies=proxies, timeout=15)
                response.raise_for_status()
                
                data = response.json()
                
                if data.get('success') and data.get('data'):
                    products = data['data']
                    
                    for product in products:
                        product_symbol = product.get('s', '')
                        tags = product.get('tags', [])
                        
                        if product_symbol:
                            self.products_data[product_symbol] = tags
                
                # ä¿å­˜ç¼“å­˜
                self.save_cache_with_expiry(self.products_cache, self.products_data)
                
                logger.info(f"è·å–åˆ°{len(self.products_data)}ä¸ªäº§å“æ ‡ç­¾æ•°æ®")
            
            # ä»ç¼“å­˜ä¸­è·å–æ ‡ç­¾
            return self.products_data.get(symbol, [])
            
        except Exception as e:
            logger.error(f"è·å–{symbol}æ ‡ç­¾å¤±è´¥: {str(e)}")
            return []

    def send_wework_notification(self, symbol: str, analysis_data: Dict[str, Any]):
        """
        å‘é€ä¼ä¸šå¾®ä¿¡ç¾¤æœºå™¨äººé€šçŸ¥
        
        Args:
            symbol: äº¤æ˜“å¯¹ç¬¦å·
            analysis_data: åˆ†ææ•°æ®
        """
        try:
            base_asset = symbol.replace('USDT', '')
            
            # æ„å»ºçªç ´æ—¶é—´åŒºé—´ä¿¡æ¯
            breakout_periods = sorted(analysis_data['breakout_periods'])
            periods_str = ', '.join([f"{days}å¤©" for days in breakout_periods])
            
            # æ„å»ºæ¶ˆæ¯å†…å®¹
            message_lines = [
                f"ğŸš€ **ä»·æ ¼çªç ´é«˜ç‚¹æé†’**",
                f"",
                f"**åˆçº¦**: {symbol}",
                f"**å½“å‰ä»·æ ¼**: ${analysis_data['current_price']:.6f}",
                f"**çªç ´åŒºé—´**: {periods_str}",
                f"",
                f"**å„æ—¶é—´åŒºé—´å¯¹æ¯”**:",
            ]
            
            # æ·»åŠ å„æ—¶é—´åŒºé—´çš„è¯¦ç»†ä¿¡æ¯
            for days in [7, 15, 30]:
                if days in analysis_data['breakouts']:
                    breakout_info = analysis_data['breakouts'][days]
                    status = "âœ… çªç ´" if breakout_info['is_high'] else "âŒ æœªçªç ´"
                    message_lines.extend([
                        f"â€¢ {days}å¤©: {status}",
                        f"  â”” æœ€é«˜ä»·: ${breakout_info['max_high']:.6f}",
                        f"  â”” æœ€ä½ä»·: ${breakout_info['min_low']:.6f}",
                    ])
            
            message_lines.extend([
                f"",
                f"**èµ„é‡‘è´¹ç‡ä¿¡æ¯**:",
                f"â€¢ å½“å‰è´¹ç‡: {analysis_data['funding_rate']['current_rate_percent']:.4f}%",
                f"â€¢ å¹´åŒ–è´¹ç‡: {analysis_data['funding_rate']['annualized_rate']:.2f}%",
                f"â€¢ ç»“ç®—å‘¨æœŸ: {analysis_data['funding_rate']['settlement_hours']}å°æ—¶",
                f"",
                f"**ä»£å¸ä¿¡æ¯**:",
                f"â€¢ å†å²æœ€é«˜ä»·: ${analysis_data['token_info']['ath_price']:.6f}",
                f"â€¢ å†å²æœ€ä½ä»·: ${analysis_data['token_info']['atl_price']:.6f}",
                f"â€¢ å¸‚å€¼: ${analysis_data['token_info']['market_cap']:,.0f}",
            ])
            
            # æœ‰æ¡ä»¶çš„ä¿¡æ¯é¡¹
            if analysis_data['token_info']['market_rank'] > 0:
                message_lines.append(f"â€¢ å¸‚å€¼æ’å: #{analysis_data['token_info']['market_rank']}")
            
            if analysis_data['token_info']['market_dominance'] > 0:
                message_lines.append(f"â€¢ å¸‚åœºå ç”¨ç‡: {analysis_data['token_info']['market_dominance']:.4f}%")
            
            message_lines.append(f"â€¢ å‘è¡Œæ—¥æœŸ: {analysis_data['token_info']['launch_date_str']}")
            
            if analysis_data['token_info']['website_url']:
                message_lines.append(f"â€¢ å®˜ç½‘: {analysis_data['token_info']['website_url']}")
            
            if analysis_data['token_info']['twitter_username']:
                message_lines.append(f"â€¢ Twitter: @{analysis_data['token_info']['twitter_username']}")
            
            if analysis_data['token_info']['twitter_last_update_str'] != 'Unknown':
                message_lines.append(f"â€¢ Twitteræ›´æ–°: {analysis_data['token_info']['twitter_last_update_str']}")
            
            if analysis_data['token_info']['github_url']:
                message_lines.append(f"â€¢ Github: {analysis_data['token_info']['github_url']}")
            
            if analysis_data['token_info']['repo_update_time_str'] != 'Unknown':
                message_lines.append(f"â€¢ ä»“åº“æ›´æ–°: {analysis_data['token_info']['repo_update_time_str']}")
            
            # æ·»åŠ å‰©ä½™çš„å›ºå®šä¿¡æ¯
            message_lines.extend([
                f"",
                f"**åˆçº¦æè¿°**: {analysis_data['description'][:100]}..." if len(analysis_data['description']) > 100 else f"**åˆçº¦æè¿°**: {analysis_data['description']}",
                f"",
                f"**æ ‡ç­¾**: {', '.join(analysis_data['tags'])}" if analysis_data['tags'] else "**æ ‡ç­¾**: æ— ",
                f"",
                f"**æ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"
            ])
            
            # è¿‡æ»¤ç©ºè¡Œ
            message_lines = [line for line in message_lines if line is not None and line != ""]
            message_content = "\n".join(message_lines)
            
            # å‡†å¤‡è¯·æ±‚æ•°æ®
            payload = {
                "msgtype": "markdown",
                "markdown": {
                    "content": message_content
                }
            }
            
            # å‘é€è¯·æ±‚
            response = requests.post(
                self.webhook_url,
                json=payload,
                proxies=proxies,
                timeout=10
            )
            
            if response.status_code == 200:
                result = response.json()
                if result.get('errcode') == 0:
                    logger.info(f"âœ… æˆåŠŸå‘é€{symbol}çªç ´é€šçŸ¥åˆ°ä¼ä¸šå¾®ä¿¡ç¾¤")
                else:
                    logger.error(f"âŒ å‘é€{symbol}é€šçŸ¥å¤±è´¥: {result}")
            else:
                logger.error(f"âŒ å‘é€{symbol}é€šçŸ¥å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
                
        except Exception as e:
            logger.error(f"âŒ å‘é€{symbol}ä¼ä¸šå¾®ä¿¡é€šçŸ¥å¤±è´¥: {str(e)}")

    def analyze_symbol(self, symbol: str) -> bool:
        """
        åˆ†æå•ä¸ªäº¤æ˜“å¯¹
        
        Args:
            symbol: äº¤æ˜“å¯¹ç¬¦å·
            
        Returns:
            bool: æ˜¯å¦å‘ç°ä»·æ ¼çªç ´
        """
        try:
            logger.debug(f"åˆ†æäº¤æ˜“å¯¹: {symbol}")
            
            # è·å–30åˆ†é’ŸKçº¿æ•°æ®
            klines = self.get_30min_klines(symbol, days=self.days_to_analyze)
            if not klines:
                return False
            
            # æ£€æŸ¥å¤šä¸ªæ—¶é—´åŒºé—´çš„ä»·æ ¼çªç ´
            breakout_result = self.check_price_breakouts(klines)
            
            if not breakout_result['has_breakout']:
                return False
            
            current_price = breakout_result['current_price']
            breakout_periods = breakout_result['breakout_periods']
            periods_str = ', '.join([f"{days}å¤©" for days in sorted(breakout_periods)])
            
            logger.info(f"ğŸ¯ å‘ç°ä»·æ ¼çªç ´: {symbol} å½“å‰ä»·æ ¼ ${current_price:.6f} çªç ´ {periods_str} é«˜ç‚¹")
            
            # è·å–åŸºç¡€èµ„äº§
            base_asset = symbol.replace('USDT', '')
            
            # è·å–è¡¥å……ä¿¡æ¯
            funding_rate_info = self.get_funding_rate_info(symbol)
            token_info = self.get_token_info(base_asset)
            description = self.get_symbol_description(base_asset)
            tags = self.get_symbol_tags(symbol)
            
            # ç»„åˆåˆ†ææ•°æ®
            analysis_data = {
                'current_price': current_price,
                'breakout_periods': breakout_periods,
                'breakouts': breakout_result['breakouts'],
                'funding_rate': funding_rate_info,
                'token_info': token_info,
                'description': description,
                'tags': tags
            }
            
            # å‘é€é€šçŸ¥
            self.send_wework_notification(symbol, analysis_data)
            
            return True
            
        except Exception as e:
            logger.error(f"åˆ†æ{symbol}å¤±è´¥: {str(e)}")
            return False

    def run_scan(self):
        """
        è¿è¡Œæ‰«æ
        """
        logger.info(f"ğŸš€ å¼€å§‹æ‰«æBinanceåˆçº¦ä»·æ ¼çªç ´ï¼ˆ{self.days_to_analyze}å¤©å†å²æ•°æ®ï¼‰...")
        
        # è·å–æ‰€æœ‰åˆçº¦ç¬¦å·
        symbols = self.get_all_futures_symbols()
        if not symbols:
            logger.error("âŒ æœªè·å–åˆ°åˆçº¦äº¤æ˜“å¯¹ï¼Œæ‰«æç»ˆæ­¢")
            return
        
        logger.info(f"ğŸ“Š å¼€å§‹æ‰«æ {len(symbols)} ä¸ªåˆçº¦äº¤æ˜“å¯¹...")
        
        found_count = 0
        processed_count = 0
        
        for i, symbol in enumerate(symbols, 1):
            try:
                logger.info(f"ğŸ“ˆ [{i}/{len(symbols)}] æ­£åœ¨åˆ†æ {symbol}...")
                
                # åˆ†æäº¤æ˜“å¯¹
                is_breakthrough = self.analyze_symbol(symbol)
                
                if is_breakthrough:
                    found_count += 1
                
                processed_count += 1
                
                # é¿å…APIé™åˆ¶ï¼Œæ·»åŠ çŸ­æš‚å»¶è¿Ÿ
                time.sleep(0.1)
                
            except Exception as e:
                logger.error(f"âŒ å¤„ç†{symbol}æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
                continue
        logger.info(f"âœ… æ‰«æå®Œæˆ! å¤„ç†äº† {processed_count} ä¸ªäº¤æ˜“å¯¹ï¼Œå‘ç° {found_count} ä¸ªä»·æ ¼çªç ´")


def parse_arguments():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(description='Binanceä»·æ ¼é«˜ç‚¹æ‰«æå™¨')
    parser.add_argument(
        '--days', 
        type=int, 
        default=30, 
        help='å†å²Kçº¿åˆ†æå¤©æ•° (é»˜è®¤: 30å¤©)'
    )
    return parser.parse_args()


def main():
    """ä¸»å‡½æ•°"""
    try:
        # è§£æå‘½ä»¤è¡Œå‚æ•°
        args = parse_arguments()
        
        logger.info(f"å¯åŠ¨å‚æ•°: å†å²åˆ†æå¤©æ•° = {args.days}å¤©")
        
        scanner = BinancePriceHighScanner(days_to_analyze=args.days)
        scanner.run_scan()
        
    except KeyboardInterrupt:
        logger.info("âŒ ç”¨æˆ·ä¸­æ–­æ‰«æ")
    except Exception as e:
        logger.error(f"âŒ æ‰«æè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")


if __name__ == "__main__":
    main() 